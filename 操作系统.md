 

# 操作系统

【考查目标】

　　1.掌握操作系统的基本概念、基本原理和基本功能，理解操作系统的整体运行过程。

　　2.掌握操作系统进程、内存、文件和I/O管理的策略、算法、机制以及相互关系。

　　3.能够运用所学的操作系统原理、方法与技术分析问题和解决问题，并能利用C语言描述相关算法。

# 一、操作系统概述

## （一)操作系统的概念、特征、功能和提供的服务

#### 概念：

操作系统是指控制和管理整个计算机系统的硬件与软件资源，合理组织调度计算机工作与资源分配，进而为用户和其他软件提供方便接口与环境的程序集合。操作系统时计算机系统中最基本的系统软件。

#### 特征：

1. 并发：两个或多个时间在同一时间间隔内发生，即计算机系统中同时存在多个运行的程序。并发（同一时间间隔）和并行（同一时刻）的区别：并发在宏观上是同时执行的，但在微观上是串行分时交替的；并行需要相关硬件支持。操作系统的并发通过分时来实现。
2. 共享：资源可以被多个并发执行的进程共同使用，分为互斥共享方式和同时访问方式；互斥共享的资源称为临界资源或独占资源，在一段时间内只能由一个进程访问，计算机中大部分物理设备和栈、变量、表格都是临界资源。同时访问方式在微观上仍然是”分时共享“的，但在宏观上同时，如磁盘等。并发和共享是操作系统最基本的两个特征，两者互为存在的条件。
3. 虚拟：把一个物理上的实体变成若干逻辑上的对应物，实现虚拟的技术称为虚拟技术。操作系统中利用了多种虚拟技术来实现虚拟处理器、虚拟内存和虚拟外部设备。通过虚拟可以是临界资源变成共享设备。主要的虚拟技术可以归纳为：时分复用（处理器等）；空分复用（存储器等）
4. 异步：进程走走停停，以不可预知的速度推进，就是异步性。异步性可能导致进程产生时间相关的错误，而操作系统需要保证多次运行进程后 结果相同。

#### 功能和服务：

1. 系统资源的管理者：
   1. 处理器管理：在多道程序环境下，处理器的分配和运行以进程（或线程）为基本单位，所以处理器管理可以归结为进程管理，主要包括进程控制、进程同步、进程通信、死锁处理、处理机调度等。
   2. 存储器管理：包括内存分配与回收、地址映射、内存保护与共享和内存扩充。
   3. 文件管理：计算机中的信息由文件形式存在，由操作系统中的文件系统负则文件管理，包括文件存储空间管理、目录管理和文件读写管理和保护。
   4. 设备管理：主要任务是完成用户I/O请求，方便用户使用设备，提高设备利用率，主要包括缓冲管理、设备分配、设备处理和虚拟设备。
2. 用户和硬件之间的接口：
   1. 命令接口：用户利用操作命令来控制执行，分为联机和脱机两种命令接口，联机命令接口又称交互式命令接口，用于分时或实时系统，用户每输入一条指令就由操作系统的命令解释程序解释并执行，强调交互性。脱机命令接口又称为批处理命令接口，适用于批处理系统，系统调度到作业时，命令解释程序逐条执行命令说明书上的命令，间接控制作业运行。
   2. 程序接口：由一组程序调用（也称广义指令）组成，用户在程序中使用这些系统调用来请求操作系统服务，最流行的是GUI图形接口，GUI最终也是通过调用程序接口实现的，严格来说，图形接口不是操作系统的一部分，但图形接口调用的系统调用命令是操作系统的一部分。
3. 扩展机器：没有软件的计算机称为裸机，裸机在最里层，外面是操作系统，覆盖软件的机器就可以称为扩充机器或虚拟机。

本门课程重点在于操作系统如何控制协调处理器、存储器、设备和文件，对于接口和扩充机器，只需要理解。

库函数：库函数是语言或应用程序的一部分，运行在用户空间中，而系统调用是操作系统的一部分，是内核位用户提供的程序接口，运行在内核空间中。部分库函数通过系统调用实现功能，通常比不调用的指令慢，因为调用需要上下文的切换和状态的转换（用户态转向核心态）。

## （二)操作系统的发展与分类

1. 无操作系统（手工操作阶段）：对应一代机（1946-1957），所有工作需要人工干预，两个突出缺点：用户独占全机，不会出现等待资源的情况，但资源利用率低；CPU等待手工操作，利用不充分。唯一解决办法是用高速的机器代替较慢的手工操作来进行控制。后期出现脱机处理，不需要完全人工干预，减少了CPU空闲时间。
2. 批处理阶段（操作系统开始出现）：对应二代机（1958-1964，晶体管，Fortran），早期使用单道批处理系统，具有自动性（作业自动逐个完成）、顺序性（各道作业顺序进入内存）和单道性，内存中仅有一道程序运行，监督程序每次只从磁带上调入一道程序运行，只有完成或发生异常后，才换入后继程序进入内存运行。问题是在运行期间发出I/O请求后，等待低速I/O设备，导致CPU利用率低。后期引入多道程序设计技术，产生多道批处理系统。允许多个程序进入内存，并在CPU内交替运行，共享软硬件资源，从而使系统各组成部分尽可能”忙碌“，因此切换任务花费时间少，效率提高。特点是多道、宏观上并行，微观上串行。主要的问题有，如何分配处理器、内存分配、I/O设备分配以及如何组织和存放大量程序和数据，保证安全性和一致性。优点有：多道程序共享资源，资源利用率高，吞吐量大，保持设备”忙碌“状态，缺点是用户响应时间长，不提供人机交互能力，用户不了解程序运行情况，也不能控制计算机。
3. 分时操作系统：对应三代机（1965-1971，中小规模集成电路），分时技术就是把处理器运行时间分成很短的时间片，按照时间片轮转把处理器分配给各联机作业使用，若在分配到的时间片内不能完成，则暂停运行等待下一轮。分时操作系统是多个用户通过终端同时共享一台主机，用户可以和主句进行交互操作而互不干扰，支持多道程序设计，但不同于多道批处理系统，分时系统实现了人机交互，所以主要特征有：同时性（多路性），指多个终端用户同时使用一台计算机，交互性，独立性和及时性。
4. 实时操作系统RTOS：（Real Time Operate System）。为了能在某个限制时间内完成紧急任务而无需时间片排队，诞生了RTOS，时间限制分为两种：必须绝对在规定时刻（或规定时间范围内）完成，则为硬实时系统，如飞机控制系统；能够接受偶尔违反规定时间且不会引起永久性损害则为软实时系统，如订票系统、银行管理系统。实时系统的主要特点是可靠性和及时性。
5. 网络操作系统和分布式计算机系统：网络操作系统最主要的特点是网络中各种资源的共享以及各台计算机之间的通信。分布式的特点是分布性和并行性，与网络操作系统本质区别是若干计算机协同完成同一任务。分布式系统通常满足以下条件：1.通过通信交换信息；2.每台计算机地位相同；3.每台计算机的资源为所有用户共享；4.任意台计算机可以构成一个子系统，并能重构；5.任何工作可以分布在几台计算机上，并行工作协同完成。
6. 个人计算机操作系统：目前使用最广泛的操作系统。

## （三)操作系统的运行环境
### 1.内核态与用户态

CPU执行两种不同性质的程序，内核程序和用户自编程序。内核程序可以执行一些特权指令（如操作I/O、中断、程序状态字、用于内存保护的寄存器），内核程序运行在内核空间，运行内核程序时，CPU运行在内核态（管态、核心态），而CPU在用户态（目态）运行用户程序。内核态和用户态是CPU状态的划分。

不同系统对于内核的定义不同，大多数包括以下四方面：

1. 时钟管理：（可以实现计时、中断、进程切换等，系统管理的方方面面都依赖于时钟）
2. 中断机制：现代操作系统是靠中断驱动的软件，但中断机制中只有一部分属于内核，如保护恢复现场，转移控制权等，以提高系统并行处理能力。
3. 原语：处于操作系统最底层，是最接近硬件的部分；原子性，不可再分；时间较短，调用频繁。具有以上三个特点的称为原语（Atomic Operation），定义原语的直接方法是关闭中断，完成后开中断。系统中的驱动、CPU切换、进程通信等的部分操作可以定义为原语，成为内核的一部分。
4. 系统控制的数据结构和处理：如作业控制块、PCB进程控制块、设备控制块、消息队列、缓冲区、内存分配表等，相关常见操作有：
   1. 进程管理，进程状态管理、调度、分派、创建与撤销
   2. 存储器管理，空间分配回收，内存信息保护、代码兑换程序等
   3. 设备管理，缓冲区管理，设备分配回收等

综上所述，核心态指令主要包括系统调用类指针和针对时钟、中断和原语的操作指令。



### 2.中断、异常

中断和异常是从用户态到核心态转换的唯二途径。中断实现了将程序未使用的某种资源的占有权释放。

中断也叫外中断，指来自CPU指令之外的事件发生，一般是强迫中断，包括外设干预和人为请求。

异常也叫内中断，例外或Trap陷阱，源自CPU执行指令内部的事件，分为自愿中断和强迫中断，自愿中断来自某些指令，强迫中断则来自软硬件异常，异常不能屏蔽，应该立即处理。

中断处理的过程：一般流程如下：1. 关中断；2. 保存断点；3. 引出中断服务程序； 4. 保存现场和屏蔽字；5. 开中断；6. 执行中断服务程序；7. 关中断；8. 恢复现场和屏蔽字； 9. 开中断、中断返回



### 3.系统调用

用户在程序中调用系统提供的一些子功能，可以视为特殊的公共子程序，系统共享资源由操作系统统一掌管，必须通过系统调用方式提出服务请求。按照功能，大概分为以下几类：

* 设备管理
* 文件管理
* 进程控制
* 进程通信
* 内存管理

系统调用需要特权指令，需要由内核程序完成，用户程序可以通过陷入指令（Trap指令，也称访管指令）发起系统调用，而后CPU进入核心态，由核心程序完成请求，以保证系统的稳定性和安全性，由用户态转向核心态可能有：1. 系统调用；2. 中断；3. 用户程序错误状态；4. 用户程序企图执行特权指令；5.核心态转向用户态由一条特权命令完成。程序从用户态转向核心态需要使用访管指令，访管指令在用户态使用，所以不是特权指令。



## （四)操作系统体系结构

1. 大内核：将操作系统的主要功能模块作为一个紧密联系的整体运行在核心态，各模块之间共享信息，有效利用相互特性，具有无可比拟的性能优势，但因为软件需求的发展，操作系统服务越来越多，接口形式日趋复杂，继而定义了层次之间的服务结构，但因为层次间交互关系复杂，很难定义清晰的层次接口，复杂交互关系使层次界限模糊。
2. 微内核：只将内核中最基本的功能保留在内核，其他不需要在核心态执行的功能移到用户态执行，降低内核设计复杂性，移出内核的代码按照分层原则划分为若干服务程序，执行相互独立，交互则借助于微内核进行通信。微内核有效分离了内核与服务，服务与服务，使接口清晰，降低维护成本，保证可靠性，但是由于频繁切换核心态和用户态，执行开销偏大，但实验数据表明，体系结构不是性能下降主要因素，体系结构的性能提升足以弥补开销带来的缺陷。
3. 库操作系统：为了减少切换开销，提出将系统服务作为运行库链接到用户程序，即库操作系统。

# 二、进程管理

## （一)进程与线程

传统的程序是指令的集合，是一个静态概念，无法描述程序执行状态以及和其他程序之间的关系，不能很好的反映并发执行过程。所以有了进程（进行中的程序）

### 1.进程概念

在躲到程序环境下，多个程序并发导致程序失去了封闭性，具有了间断性和不可再现的特性，所以有了进程的概念，以便更好地描述和控制程序的并发执行，实现并发和共享两个操作系统基本特性。为了使并发执行的程序和数据能够独立运行，配置了一个专门的数据结构，即PCB（Process Control Block），进程控制块。由程序段、相关数据段和PCB三部分就构成了进程映像（进程实体），创建和撤销进程就是创建撤销PCB。进程映像使静态的，进程是动态的。PCB是进程存在的唯一标志。进程的定义有：

1. 程序的而一次执行过程
2. 一个程序及其数据在处理机上顺序执行时所发生的活动。
3. 具有独立功能的程序在一个数据集合上运行的过程，是系统进行资源分配和调度的一个独立单位。
4. 进程是进程实体的运行过程，是系统进行资源分配和调度的一个独立单位。



#### 特征：

1. 动态性：进程是程序的一次执行，有创建、活动、暂停、终止等过程，具有lifespan，动态消亡
2. 并发性：多个进程同时存在内存中，能同时运行，这也是操作系统的重要特征。
3. 独立性：是一个能独立运行、获得资源、接受调度的基本单位。
4. 异步性：执行上的间断性，即各程序按照独立的速度推进，导致执行结果不可再现，所以需要同步机制。
5. 结构性：要配置PCB进行描述。



### 2.进程的状态与转换

通常有五个状态，前三者是基本态：

1. 运行态：正在CPU上运行，单处理机环境下，每个时刻最多一个进程处于运行态。
2. 就绪态：获得了除了CPU以外的一切资源，可以立即运行。
3. 阻塞态（等待态）：等待某一事件而暂停，或等待其他资源就绪，或等待I/O完成，即使CPU空闲也不能运行。
4. 创建态：正在创建，尚未就绪，一般需要先申请PCB，并写入控制和管理信息，然后分配资源，才能进入就绪态。
5. 结束态：正在从系统中消失，已经退出运行，尚未进行资源释放和回收工作。

* 就绪-->运行：被调度后，获得处理器资源
* 运行-->就绪（被动）：时间片用完后，不得不让出处理机，或者是在可剥夺的操作系统中有更高优先级的进程就绪
* 运行-->阻塞（主动）：请求某一资源或等待某一时间，这是一种特殊的由用户程序调用操作系统内核的形式。
* 阻塞-->就绪（被动）：等待事件到来或操作、中断结束



### 3.进程控制

一般进程控制用的程序是原语，是一个不可分割的基本单位。主要的控制行为有以下几种：

1. 进程创建：父进程创建子进程，子进程可以继承父进程的资源，撤销时归还，撤销父进程的同时应该撤销所有子进程。（linux下若没有撤销子进程，子进程成为孤儿进程，由init托养，init进程没有父进程）。创建原语如下：

   1. 为新进程分配一个PID，并申请一个PCB，若申请失败（PCB有限）则创建失败。
   2. 分配资源，为程序和数据及用户栈内存空间，若空间不足，停在创建态等待资源（而不是创建失败）
   3. 初始化PCB，包括初始化标志、状态、控制信息，以及优先级
   4. 若就绪队列能接纳，则加入就绪队列，等待被调度运行。

2. 进程终止：引起终止的事件可能有：:one:正常结束，:two:异常结束，如越界、非法指令、算术错误、I/O故障，:three:外界干预，如操作系统干预、父进程请求等。终止进程（撤销原语）如下：

   1. 根据PID，检索PCB，读出状态
   2. 处于执行态则立即终止执行，将处理机资源分派给其他进程。
   3. 若有子孙进程，终止所有子孙进程。
   4. 将全部资源归还给父进程或操作系统
   5. 将PCB从队列（链表）中删除

3. 进程阻塞和唤醒：阻塞原语是一种进程主动行为，只有处于运行态的进程才可能转为阻塞态。阻塞原语(Block)如下：

   1. 找到要阻塞PID对应的PCB。
   2. 若程序为运行态，保护现场，将状态转换为阻塞，停止运行
   3. 把PCB插入对应事件的等待队列，将处理机资源调度给其他就绪进程。

   阻塞事件完成后，调用唤醒原语(Wakeup)如下：

   1. 在事件等待队列中找到对应PCB
   2. 从等待队列溢出，状态变为就绪态
   3. 插入就绪队列，等待调度程序调度。

   Block和Wakeup必须成对使用，Block是进程自我调用实现的，Wakeup则由一个与被唤醒进程合作或被其他相关的进程调用实现的。

4. 进程切换：切换不等于调度，调度是决定将资源分配给那个进程的行为，是一种决策行为；而切换是指实际分配的执行行为，一般来说，现有调度后有切换。切换在内核态完成，进程切换和处理器模式切换不同，模式切换在切回用户态后，继续运行用户程序，所以进程环境无需更改，而进程切换还要求进行环境更改。具体切换执行过程如下：

   1. 保存处理机上下文，包括PC和其他寄存器
   2. 更新PCB信息
   3. 把进程的PCB移入相应队列，如就绪或阻塞
   4. 选择另一个进程执行，并更新其PCB
   5. 更新内存管理的数据结构
   6. 恢复处理机上下文。



### 4.进程组织

进程的组织结构包括三个部分，最重要的是进程控制块PCB。具体如下：

1. 进程控制块：进程创建后，PCB就常驻内存，任意时刻可以存取，并在结束时删除，PCB是进程实体的一部分，是进程存在的唯一标志。操作系统通过PCB进行控制：准备调度时通过PCB查询状态和优先级；调度到后需要根据PCB保存的处理机状态信息，设置恢复运行的现场，并根据PCB中的程序数据内存地址，找到程序和数据；进程同步或通信需要访问PCB；进程暂停时，断点的处理机环境保存在PCB中；进程结束后释放PCB。PCB主要包括以下内容：

   1. 进程描述信息：进程标识符PID，用户标识符UID
   2. 进程控制和管理信息：如当前状态、优先级、代码入口地址、程序外存地址、进入内存时间、处理器占用时间、信号量使用
   3. 资源分配清单：代码段指针、数据段指针、堆栈段指针、文件描述符、键盘、鼠标
   4. 处理器相关信息：通用寄存器值、地址寄存器值、控制寄存器值、状态寄存器值、状态字

   PCB常用的组织方式有队列方式和索引方式，队列方式将同一状态的PCB链接成一个队列，根据阻塞的原因的不同，排成多个阻塞队列；索引方式则放入索引表，表项指向相应PCB，不同状态对应不同的索引表。

2. 程序段：程序代码段，一个程序段可以为多个进程共享。

3. 数据段：可以是原始数据，也可以是程序执行产生的中间或最终结果。



### 5.进程通信

进程通信是进程之间的信息交换方式，PV操作是低级通信方式，高级通信方式是以较高效率传输大量数据的通信方式，主要有以下三种：

1. 共享存储系统：低级的共享是基于数据结构的共享，高级的共享是基于存储区的共享。通信进程间存在一块可以直接访问的共享空间，可以通过对这片空间的读写操作进行信息交换，操作系统只提供空间和同步互斥工具（如P操作、V操作），数据交换由用户自己安排读写指令完成。用户进程空间一般是独立的，两个用户进程共享空间必须通过特殊的系统调用实现，但进程内的线程是自然共享进程空间的的。
2. 消息传递：数据交换以格式化的消息为单位，进程通过操作系统提供的消息传递方法实现通信，有发送消息和接收消息两个原语。直接通信方式就是发送进程直接把消息发给接收进程，间接通信方式通过中间实体，即信箱完成。这种通信方式又叫信箱通信方式。
3. 管道通信：管道是一个连接读进程和写进程以实现通信的一个共享文件，又名pipe文件，写进程以字符流的方式将大量数据写入管道，输出则读出，数据是一次性操作，一旦被读取就会被抛弃以释放空间，管道可以克服文件通信的两个问题，具体如下：1. 限制管道的大小，管道是一个固定大小的缓冲区。2. 管道变空则read()被阻塞，管道满则write()被阻塞。缓冲区只允许一边写入一边读出，所以只能是半双工通信。所以父子进程需要互相通信的话需要两个管道。



### 6.线程概念与多线程模型

引入进程是为了更好地使多道程序并发执行，提高资源利用率和系统吞吐率；而引入线程就是为了减小程序并发执行付出的时空开销，提高并发性能。

#### 线程：

最直接的理解就是”轻量级进程“，是一个基本的CPU执行单元，也是程序执行流的最小单位，由线程ID、程序计数器、寄存器集合和堆栈组成，线程是进程中的一个实体，不拥有系统资源，可与进程中的其他线程共享全部资源，线程可以创建撤销另一个线程，同一进程中的多个线程可以并发执行，线程也呈现间断性，拥有就绪、阻塞、运行三种基本状态。

引入线程后，进程的内涵就发生了变化，进程作为除CPU以外系统资源的分配单位，而线程成为处理机的分配单元，若线程的切换发生在同一个进程内，则只需要很少的时空开销。

#### 进程和线程的比较：

1. 调度：同一进程中线程的切换不会引起进程切换，引入线程后，线程成为了独立调度的基本单位，进程只是拥有资源的基本单位。
2. 拥有资源：进程使拥有资源的基本单位，线程不拥有系统资源，但线程也可以访问其进程的系统资源。
3. 并发性：进程之间可以并发，线程之间也可以并发，线程使操作系统具有更好地并发性，提高了系统的吞吐量。
4. 系统开销：创建和撤销进程的开销远大于线程的开销，线程切换的系统开销也很小，线程之间的同步与通信也容易实现。
5. 地址空间和其他资源：进程的地址空间互相独立，同一进程的各线程共享进程地址空间。
6. 通信方面：进程间通信IPC，需要进程同步和互斥手段辅助保证数据一致性，线程之间可以直接读写进程数据段（如全局变量）进行通信，容易实现，甚至无需操作系统干预。

#### 线程属性：

1. 线程是一个轻型实体，不拥有系统资源，但有一个唯一的标识符和一个线程控制块，记录线程执行的寄存器和栈等现场状况。
2. 不同线程可以执行相同程序
3. 同一进程中的各个线程共享进程拥有的资源
4. 线程是独立调度单位，多个线程可以并发执行
5. 线程具有生命周期，会经历阻塞态、就绪态和运行态等状态变化。

#### 多线程模型：

线程分为两类，用户级线程（User-level Thread，ULT）和内核级线程（Kernel-Level Thread，KLT），内核级线程又叫内核支持的线程。用户级线程的管理工作都有应用程序完成，内核级则由内核完成创建撤销切换等管理工作。组合方式的多线程实现就是将ULT映射到KLT上，常见的连接方式（多线程模型）如下：

1. 多对一模型：多个用户级线程映射到同一个内核级线程，线程管理在用户空间完成，用户级线程对操作系统透明，优点是效率高，缺点是一个进程在使用内核服务阻塞时，整个进程都被阻塞，多个线程不能并行运行在多处理机上。
2. 一对一模型：每一个用户级线程映射到一个内核级线程，优点是并发能力强，缺点是创建线程的开销大，影响性能。
3. 多对多模型：n各用户级线程映射到m各内核级线程，m>=n，实际上是一种折中，克服了前两者的缺点。 

## （二)处理机调度

### 1.调度的基本概念

调度就是对处理机进行分配，从就绪队列中按照一定的算法（公平、高效）选择一个进程，并将处理机分配给他运行，以实现程序的并发执行。处理机调度时多道程序操作系统的基础，是操作系统设计的核心问题。

一个作业的调度往往需要经历三个层次：

1. 作业调度，又称高级调度，给外存中的后备作业分配资源，建立进程，是辅存和内存之间的调度，对于每个作业只进行一次调入一次调出。多道批处理系统大都有作业调度，其他系统通常不需要配置，一般几分钟执行一次。
2. 中级调度，又称内存调度，将暂时不运行的调度到外存，进入挂起态，将就绪进程调入到内存。
3. 进程调度，又称低级调度，最基本的一种调度，不可或缺，频率高，一般几十毫秒一次。



### 2.调度时机、切换与过程

进程调度和切换程序是系统内核程序，请求调度的事件发生后，才运行进程调度程序，调度了新的就绪程序后，才会进行进程间的切换，理论上三件事应该顺序执行，但实际中事件发生后不一定马上调度切换。

不能调度和切换的情况有以下几种：:one:处理中断，中断是系统工作的而一部分，逻辑上不属于某一进程，不应该被剥夺处理器资源。:two:进程在操作系统内核程序临界区内，由于临界区独占式访问共享数据，所以需要上锁，解锁前不应切换到其他程序，以加快释放。:three:其他需要完全屏蔽中断的原子操作过程中，如加锁解锁、中断现场保护、恢复等，练中断都要屏蔽，更不应该进行进程调度和切换。

应该进行进程调度和切换的情况如下：:one:发生引起调度条件，且当前进程无法继续运行下去，即非剥夺调度。:two:中断处理结束或自陷处理结束后，返回被中断的用户态程序执行之前，若置上请求调度标志，即可马上进行进程调度和切换，即剥夺方式的调度。

进程切换往往在调度后立即发生，一般要求保存当前切换点的现场信息，恢复被调度进程的现场信息。切换时，内核将原进程的现场信息推入当前进程的内核堆栈来保存，并更新堆栈指针。内核在完成从新进程的内核栈中装入新进程的现场信息、更新当前运行进程空间指针、重设PC寄存器等相关工作后，开始新的进程。

### 3.调度的基本准则

评价处理机调度算法性能的准则：

1. CPU利用率
2. 系统吞吐量
3. 周转时间：周转时间=作业完成时间-作业提交时间。平均周转时间=Σn个作业的周转时间/n。带权周转时间=作业周转时间/作业实际运行时间。平均带权周转时间=Σn个作业的带权周转时间/n。
4. 等待时间：指进程处于等待处理机状态的时间之和，衡量一个调度算法的优劣，常常只需要简单地考察等待时间。
5. 响应时间：用户提交请求到系统首次产生相应所用的时间，在交互式系统中，周转时间不可能式最好的评价准则，一般使用响应时间作为衡量调度算法的重要准则之一，从用户的角度来看，调度策略应该尽可能降低响应时间，使其在用户接受范围内。

设计调度程序，一方面要满足特定系统用户的要求，另一方面要考虑系统整体效率，同时还要考虑调度算法的开销。

### 4.调度方式

调度方式主要讨论当有优先权更高的进程进入就绪队列时如何分配处理机。

1. 非剥夺调度方式，又称非抢占方式，即使有优先级更高的进程进入就绪队列，也等到进程完成或进入阻塞态时，才调度处理器，优点是：简单，系统开销小，适用于大多数批处理系统，但不适用于分时系统和大多数实时系统。
2. 剥夺调度方式，又称抢占方式，当出现某个更重要或更紧迫的任务是，立即暂停当前进程，将处理机分配给紧迫任务，对与提高吞吐率和响应速率都有明显好处，但剥夺必须遵循一定的原则，主要有优先权、短进程优先、时间片原则等。

### 5.典型调度算法

#### 1. 先来先服务调度算法FCFS

First Come First Serve，最简单，既适用于作业调度，也适用于进程调度。每次选择一个最先进入就绪队列的进程，直到完成或阻塞才释放处理机，属于不可剥夺算法，从表面上看对所有算法公平，但如果长作业先到达，则之后的短作业需要等待很长时间，因此不能作为分时系统和实时系统的主要调度策略，但常被结合在其他调度策略中使用，如优先级中，同一优先级往往采用FCFS。

特点是算法简单，效率低，对长作业有利，对短作业不利（相比于SJF和高响应比），有利于CPU繁忙型而不利于I/O繁忙型。

#### 2. 时间片轮转调度算法

主要适用于分时系统的进程调度，按照到达时间先后拍成队列，即先来先服务，但每个进程只能运行一个时间片，属于剥夺算法，时间片结束后，即使未运行完成，也会被剥夺，并返回到就绪队列的队尾。算法中最关键的是时间片的大小，时间片足够大，使所有进程都能在一个时间片内执行完成，则退化为FCFS，若时间片太小，处理机频繁切换，开销过大。时间片一般由系统响应时间、就绪队列中的进程数和系统的处理能力等因素确定。

#### 3.短作业（短进程、线程）优先调度算法，SJF

Short Job First， 可用于作业调度，也可用于进程、线程调度，属于不可剥夺算法，每次从就绪队列中选择一个估计运行时间最短的进程，直到完成或阻塞才释放处理机。优点是平均等待时间和平均周转时间最短，缺点是:one:对长作业不利，可能导致长作业”饥饿“现象。:two:未完全考虑紧迫程度，不能保证紧迫任务被处理。:three:作业长短由用户提供的估计执行时间决定，用户可能会有意缩短作业运行时间，所以不一定能真正做到短任务优先。

#### 4. 优先级调度算法

既可用于作业，也可用于进程调度。根据是否抢占正在执行的程序，分为

1. 非剥夺式优先级调度算法
2. 剥夺式优先级调度算法

根据优先级是否改变，可以分为：

1. 静态优先级：优先级在创建进程时确定，在进程的整个运行期间保持不变，确定依据主要有进程类型、进程对资源的要求、用户要求
2. 动态优先级：进程运行过程中，根据进程变化动态调整优先级，主要依据有：占用CPU时间长短、就绪队列等待CPU时间长短等。

优先级设置的原则：

1. 系统进程高于用户进程
2. 交互型高于非交互性进程（前台进程高于后台进程）
3. I/O进程高于计算型进程：让较慢的I/O设备尽早开始工作，来提升系统的整体效率。

#### 5. 高响应比优先调度算法

高响应比优先调度算法主要用于作业调度，是对FCFS和SJF的一种总和平衡，考虑了每个作业的等待时间和估计的运行时间，每次调度选择响应比最高的作业运行，响应比R~p~=（等待时间+要求服务时间）/要求服务时间，由此可知，等待时间相同时，要求服务时间短的响应比高，有利于短作业，要求服务时间相同时，先来先服务，对于长作业，响应比随着等待时间增加而提高，避免了饥饿状态。

#### 6. 多级反馈队列调度算法

多级反馈是时间片轮转和优先级调度的综合和发展，通过动态调整优先级和时间片大小，兼顾多方面系统目标。是剥夺算法，主要用于进程调度，主要思想有：

1. 设置多个就绪队列，优先级不同，1级队列优先级最高每个队列的时间片不同，优先级越高，时间片越短，如第2级比第1级长一倍，，第i+1级比第i级长一倍。
2. 一个新进程进入内存后，首先放入第1级队列末尾，按照FCFS原则排队，若能在时间片内完成则撤离，若未完成，则沉入下一级队列末尾，在任意级队列内，采用时间片轮转的方式运行。
3. 只有在高优先级队列为空的时候，才调度低优先级进程，有进程加入高优先级队列，则抢夺运行进程，将处理机分配给高优先级的作业。

优势有：对于终端型用户来说短作业优先，对于短批处理作业系统来说周转时间短，对于长批处理作业用户来说，经过前几个队列至少能部分执行。是目前最通用的算法，但设计复杂

## （三)同步与互斥

### 1.进程同步的基本概念

临界资源：一次仅允许一个进程使用的资源称为临界资源，访问临界资源的那段代码称为临界区，为了保证临界资源的正确使用，可以将临界资源的访问过程分为四个部分:one:进入区，检查是否可以进入临界区，设置标志阻止其他进程访问 :two: 临界区，又称临界段​ :three:退出区，将正在访问临界区的标志清除​ :four: 剩余区，代码的其他部分。​

同步：也叫直接制约关系，指多个进程之间因为工作次序而等待，或传递信息所产生的制约关系，制约关系源于相互合作。

互斥：间接制约关系，当一个进程进入临界区使用临界资源时，另一个进程必须等待。必须遵循以下准则：:one:空闲让进 :two:忙则等待​ :three:有限等待，能保证在有限时间内进入临界区；:four:让权等待​，等待时需要释放处理器，防止进程忙等待。

### 2.实现临界区互斥的基本方法

#### 软件实现方法：

1. 单标志法：公用int turn，指明允许进入的进程编号，可以确保每次只进一个，但必须轮流交替进入，一个进程不在进入另一个进程也不能再进，会违背空闲让进，导致资源利用不充分。
2. 双标志先检查：双标志指的是两个进程各有一个flag[i]，在每次进入临界区前，需要检查临界区是否被访问，即对方的flag是否为true，优点是不用交替，可以连续使用，缺点是可能同时进入，检查完对方flag和切换自己的flag之间有一段时间，导致违背忙则等待原则。
3. 双标志后检查：先将自己的标志设为true，在检查对方标志是否为true，但可能导致饥饿现象，即两个进程同时设置为true，但谦让导致谁也进不了临界区。
4. Peterson’s Algorithm：结合了单标志和后检查，每个变量设置自己的flag后再设置turn，这时同时检测两一个进程状态标志和不允许进入标志，利用flag解决互斥访问和利用turn解决饥饿现象

#### 硬件实现方法

用硬件支持临界段问题的方法称为低级方法，或元方法。

1. 中断屏蔽：在一个进程用处理机执行临界区代码时，为了防止其他进程进入临界区，禁止一切中断，称之为中断屏蔽或关中断，中断屏蔽能保证临界区代码顺利执行完，进而保证互斥正确实现，但限制了处理机交替执行程序的能力，效率降低，此外，关中断的权力交给用户不太明智，一个进程关中断后不在打开，可能导致系统终止。
2. 指令方法：:one:TestAndSet指令，作为原子操作，可以在读出标志位后设置为真，于是可以为每个临界资源设置一个共享布尔变量lock，在进程访问临界资源前检查和修改lock，若有进程在临界区，则循环重复直到程序退出。:two:Swap指令交换两个字（字节）的内容。利用上述两个指令，可以为每一个临界区设置共享布尔量lock=false，每个进程设置局部布尔量key，用于和lock交换信息，先用Swap指令交换lock和key，检查key状态，有进程在临界区，则重复交换和检查，直到进程退出。

硬件方法优点是适用于任意数目的进程，简单，容易验证正确性，可以支持进程内多个临界区，只要为每一个临界区设置一个布尔变量。缺点时进程等待进入临界区需要耗费处理机时间，不能实现让权等待，从等待程序中随机选择一个进入临界区，有的进程可能一直选不上，导致“饥饿”现象发生。

### 3.信号量

信号量是一种比较强的机制，用来解决同步互斥问题，只能被两个标准原语访问，wait(S)和signal(S)，也可记作P操作和V操作。原语不能被中断，如果中断可能出现临界段问题。

1. 整型信号量：int S，在wait操作中，只要S<=0，就会不停测试，因此处于忙等，没有遵循让权等待
  ~~~C++
  wait(S){
  	while(S<=0);
      S=S-1;
  }
  signal(S){
      S=S+1;
  }
  ~~~
2. 记录型信号量：进程链表L，和资源数目变量value，S.value<0表示资源分配完，调用block原语自我阻塞，而S++后，S.value<=0表示还有进程在等待，需要将其唤醒。
~~~ C++
typedef struct{
    int value;
    struct process *L;
}semaphore;

void wait(semaphore S){
    S.value--;
    if(S.value<0){
        add this process to S.L;
        block(S.L);
    }
}
void signal(semaphore S){
    S.value++;
    if(S.value<=0){
        remove a process P from S.L;
        wakeup(P);
    }
}
~~~
3. 同步：用资源前P操作，用资源后V操作
4. 互斥：PV操作紧夹要使用互斥资源的行为。
5. 前驱关系：为每一对前驱关系设置信号量，前驱完成后V操作申明完成，后驱使用前P操作检查是否完成。即前V后P。
6. 分析步骤：关系分析、整理思路、设置信号量



### 4.管程

分散的同步操作给系统管理带来麻烦，还容易因为同步不当造成死锁。

系统中的各类软硬件资源都能用ADT（抽象数据结构）来描述特性，而一个代表共享资源的数据结构以及对该结构实施操作的一组过程所组成的资源管理程序，就称为管程（monitor），管程定义了一个ADT和可在其上并发执行的一组操作，由四部分组成：:one:管程名称:two:内部共享结构数据说明:three:一组操作过程或函数:four:初始化语句。

~~~C++
monitor Demo{//①
    共享数据结构S;//②
    init_code(){//④
        S=5;
    }
    take_away(){//③
        对S的一系列处理;
        S--;
    }
    give_back(){
        对S的一系列处理;
        S++;
    }
}
~~~

管程与类相似，将操作封装起来，每次只允许一个进程进入管程，实现互斥。

条件变量：导致进程进入管程后的阻塞原因定义为条件变量，管程中一般设置多个条件变量，并为每一个条件变量设置一个的等待队列，对于一个条件变量x有x.signal()在x条件变化时唤醒一个因为x条件阻塞的进程，以及x.wait()将因为x阻塞的进程插入等待队列。

条件变量和信号量：相同点，wait和signal与P操作、V操作类似，可以实现阻塞唤醒。不同点：条件变量是没有值的，仅实现排队等待功能，剩余资源数由共享数据结构记录，而信号量是有值的，值反映了剩余资源数。

### 5.经典同步问题

#### 1. 生产者-消费者问题

一组生产者和一组消费者共享一个初始为空，大小为n的缓冲区，只有缓冲区不满，生产者才能放入内容，否则必须等待；只有缓冲区不空，消费者才能取出内容， 否则必须等待，缓冲区是临界资源，只允许一个生产者或一个消费者进入。

1. 关系分析：生产者和消费者是互斥关系，同时只有在生产者生产后，消费者才能消费，也是同步关系。

2. 整理思路：只有两个进程，互斥同步，需要解决互斥和同步PV操作的位置

3. 信号量设置：设置mutex互斥，信号量full=0、empty=n

4. 代码描述

~~~C++
   semaphore mutex=1;
   semaphore empty=n;
   semaphore full =0;
   producer(){
       while(1){
           produce an item in nextp;
           P(empty);			//同步，用前P
           P(mutex);			//互斥紧夹
           add nextp to buffer;
           V(mutex);
           V(full);			//同步，用后V 
       }
   }
   consumer(){
       while(1){
           P(full);			//注意，同步P操作必须在互斥P操作前
           P(mutex);
           remove an item from buffer；
           V(mutex);
           V(empty);			//同步，用后V
           consume the item;
       }
   }
~~~


多生产者、多消费者问题，需要分析同步互斥关系，从事件的角度进行前后关系的分析，两个生产者可能导致写覆盖，所以需要考虑互斥。

#### 2. 读者-写者问题

有读者和写者两组并发进程，共享一个文件，允许多个读者同时读，只允许一个写者写，写者写时不允许其他人读写，写前应让其他进程全部退出。设置信号量count记录读者数量，mutex为互斥，rw读写互斥。

~~~C++
int count =0;		//记录读者数量
semaphore mutex=0;	//保护count变量互斥访问
semaphore rw=1;		//读写互斥
writer(){
    while(1){
        P(rw);
        writing;
        V(rw);
    }
}
reader(){
    while(1){
        P(mutex);		//互斥访问count
        if(count==0)	//第一个读进程读时
            P(rw);		//阻止写
        count++;
        V(mutex);		//释放count互斥
        reading;
        P(mutex);		//互斥访问count
        count--;
        if(count==0)	//最后一个读进程读完
            V(rw);		//允许写进程
        V(mutex);		//释放count
    }
}
~~~

以上算法读者优先，写操作被读操作延迟，可能导致写进程的饥饿。

以下为读写公平算法

~~~C++
int count=0;		//记录读者数量
semaphore mutex=1;	//保护count互斥
semaphore rw=1;		//保证读写互斥
semaphore w=1;		//实现读写公平，即读者和写者进入同一个阻塞队列
writer(){
    while(1){
        P(w);		//没有写进程时请求进入
        P(rw);		
        writing;
        V(rw);
        V(w);		//恢复访问
    }
}
reader(){
    while(1){
        P(w);		//没有写进程时请求进入
        P(mutex);	//互斥访问count
        if(count==0）//第一个读进程读时
            P(rw);	//阻止写进程
        count++;
        V(mutex);
        V(w);		//恢复文件访问，允许读进程进入
        reading;	
        P(mutex);
        count--;
        if(count==0)//所有读进程读完后
            V(rw);	//允许写进程写
        V(mutex);
    }
}
~~~

以下为写者优先算法：所谓优先就是在所有写者写完以后，读者才能读，但读者中的一个可以在写者阻塞前读，防止饥饿。

~~~C++
int rcnt=0,wcnt=0;
semaphore mutex_r=1,mutex_w=1,rw=1,r=1,w=1;
writer(){
    while(1){
        P(mutex_w);
        if(wcnt==0)
            P(r);	//写进程时禁止读
        wcnt++;
        V(mutex_w);
        P(w);
        writing;
        V(w);
        P(mutex_w);
        wcnt--;
        if(wcnt==0)
            V(r);
        V(mutex_w);
    }
}
reader(){
    while(1){
        P(rw);		//只允许一个进程在r上排队，其他读者进程在rw的阻塞队列中
        P(r);		//
        P(mutex_r);
        if(rcnt==0)
            P(w);	//进行第一个读进程时，禁止写
        rcnt++;
        V(mutex_r);
        V(r);
        V(rw);
        reading;
        P(mutex_r);
        rcnt--;
        if(rcnt==0)
            V(w);
        V(mutex_r);
    }
}
~~~

读者写者进程的精髓是在遇到一个不太好解决的互斥问题时，思考以下互斥访问的count计数器能否解决问题。

#### 3. 哲学家进餐问题

一张圆桌5个哲学家，5根筷子，哲学家需要左右两根筷子才能进食，否则只能等待。哲学家和邻居对于中间的筷子是互斥关系，解决方法有两个，一是同时拿两根筷子，二是对每个哲学家的动作制定规则，避免饥饿或死锁。为了避免死锁，还需要增加一些规则，如至多允许4名哲学家进餐，只有两根筷子都可用才拿两根筷子，或者顺序编号，奇数先拿左边筷子，偶数先拿右边筷子等。还可以使用AND信号量来解决。哲学家进餐是贪心的反面，贪心强调局部最优达到全局最优，哲学家进餐则需要考虑下一步情况。

采用同时拿两根筷子，两根筷子都可用才拿，代码如下：

~~~C++
semaphore chopstick[5]={1};
semaphore mutex=1;
Pi(){
    do{
        P(mutex);
        P(chopstick[i]);
        P(chopstick[(i+1)%5]);
        V(mutex);
        eat;
        V(chopstick[i]);
        V(chopstick[(i+1)%5]);
        think;
    }while(1);
}
~~~

AND型信号量：同时需要多种资源，而且每种只占一个的信号量机制，使用Swait原语（Simultaneous Wait），和Ssignal原语，在一个原语中要么将所需要的所有资源都分配给他，要么都不分配。信号量的次序只决定进程属于哪个阻塞队列，对于运行没有影响，总有进程在获得所有资源运行结束后释放，所以不会死锁。

一般信号量集：AND型的升级版，对于需要多种资源，每种资源需求量不相同的信号量机制，于AND型思想相同，要么全分配，要么都不分配。

#### 4.吸烟者问题

三个抽烟者，一个供应者，吸烟者需要3种材料，但自己只拥有1种，供应者轮流供应2种材料，

~~~C++
int random;
semaphore offer1=0;
semaphore offer2=0;
semaphore offer3=0;
semaphore finish=0;	/*finish初值为0，所以P1第一轮生产完就被阻塞
由于四个信号量最多1个为1，所以无需再设置一个mutex。*/
material offer[3]=0;
process P1(){	//生产者
    while (1){
        random=0;
      //P(finish);若P放在此，需要设置初值为1
        offer(random+1)++;//根据random供应材料
        if(random==0)
            V(offer1);	//提供烟草、纸
        else if(random==1)
            V(offer2);	//提供烟草、胶水
        else
            V(offer3);	//提供胶水、纸
        random=(random++)%3
        P(finish);	//由上分析，P必须放在这里
    }
}
process P2(){	//拥有胶水
    while(1){
        P(offer1);
        offer[0]--;makeACigratte();enjoy();
        V(finish);
    }
}
process P3(){	//拥有纸
    while(1){
        P(offer2);
        offer[1]--;makeACigratte();enjoy();;
        V(finish);
    }
}
process P4(){	//拥有烟草
    while(1){
        P(offer3);
        offer[2]--;makeACigratte();enjoy();;
        V(finish);
    }
}
~~~





## （四)死锁

### 1.死锁的概念

多个进程因为竞争资源而相互等待的僵局。

原因：

1. 系统资源竞争
2. 进程推进顺序非法：信号量使用不当或者进程运行顺序非法。
3. 具备死锁产生的四个必要条件：
   1. 互斥条件：互斥访问
   2. 不剥夺条件：不能剥夺被占用资源
   3. 请求并保持：保持现有资源的同时，请求其他资源
   4. 循环等待：每个进程需要的资源被别的进程保持着，产生循环等待链(环)。

### 2.死锁处理策略

| 方式     | 资源分配策略     | 可能模式                             | 主要优点                                     | 主要缺点                                                     | 主要思想                                                     |
| -------- | ---------------- | ------------------------------------ | -------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 死锁预防 | 保守，宁可闲置   | 一次请求所有资源，资源剥夺，按序分配 | 适用于突发式处理的进程，不必进行剥夺         | 效率低、进程初始化时间延长；剥夺次数多（初始化过程中）；不便于灵活申请新资源 | 破坏4个必要条件其中之一                                      |
| 死锁避免 | 折中             | 寻找可能的安全顺序                   | 不必进行剥夺                                 | 必须知道将来的资源需求，进程不能长时间被阻塞，实现复杂       | 在资源动态分配过程中，防止进入不安全状态                     |
| 死锁检测 | 宽松，允许就分配 | 定期检查死锁是否发生                 | 不延长进程初始化时间，允许对死锁进行现场处理 | 剥夺解除死锁，造成损失                                       | 允许发生死锁，系统机构检测，检测到死锁后，采取措施解除死锁。 |

### 3.死锁预防

1. 破坏互斥条件：即允许所有系统资源共享，一般不可行
2. 破坏不剥夺条件：适用于状态易于保存和恢复的资源，如CPU寄存器、内存，一般不能用于打印机等资源
3. 破坏请求并保持条件：采用预先静态分配方法，运行前一次申请完所有资源，未满足之前不运行，实现简单，但是系统资源浪费严重，还会导致饥饿现象，因为个别资源长期占用使等待进程迟迟不能开始运行
4. 破坏循环等待条件：可以采用顺序资源分配法，即给系统资源编号，每个进程必须按照编号递增的顺序请求资源，同类资源一次申请完。这一方法问题是编号必须稳定，限制了新设备的增加，容易发生作业所需资源顺序于系统规定资源顺序不一致，造成资源浪费，还会给用户编程带来障碍。

### 4.死锁避免

死锁避免是在资源动态分配过程中，防止系统进入不安全状态，避免死锁。限制条件弱，能获得较好的系统性能。

#### 系统安全状态



#### 银行家算法。





### 5.死锁检测和解除

#### 资源分配图

#### 死锁定理

#### 死锁解除

1. 资源剥夺法：
2. 撤销进程法：
3. 进程回退法：

# 三、内存管理

## （一)内存管理基础





### 1.内存管理概念

　　程序装入与链接;逻辑地址与物理地址空间;内存保护。





### 2.交换与覆盖





### 3.连续分配管理方式



### 4.非连续分配管理方式

非连续分配管理方式允许一个程序分散的装入不相邻的内存分区，但需要额外的空间存储索引，所以存储密度不如连续存储方式。根据分区大小是否固定，可以分为分页存储管理方式和分段存储管理方式，分页存储又根据是否需要所有页面装入内存可以分为基本存储管理方式和请求存储管理方式。请求存储管理方式基于虚拟内存实现，下述均为基本存储管理。

#### 分页管理方式

分页将主存空间华为大小相等且固定的块，块相对较小，作为主存的基本单位，进程也以块为单位划分，并以块为单位申请主存空间。形式上看，分页像分区相等的固定分区技术，分页管理不会产生外部碎片，但是因为块相对分区要小很多，同时进程也按块进行划分，所以进程只会在最后一个不完整的块申请空间时产生主存碎片，每个进程平均产生半个块大小的内部碎片，也称页内碎片。

进程中的块称为页(Page)，内存中的块称为页框或页帧（Page Frame），外村也同样划分，称为块（Block）。为了方便地址转换，页面大小应该是2的整数幂，大小适中，页面太小则会使页表过长，占用内存和硬件地址转换开销，降低换入换出效率；页面过大导致页内碎片增大，降低内存利用率。

地址结构：分页管理的内部逻辑地址包括两部分，前一部分为页号P，后一部分为页内偏移量w，地址长度32位下，页号20位，每页大小为2^12^即4KB，地址结构决定了虚拟内存的寻址空间有多大。

页表：页表的作用是实现页号到物理块号的地址映射，页表由页表项组成，存储在主存中，页表项分为两部分，第一部分为页号，第二部分为对应的物理内存块号。

地址变换过程：逻辑地址A，物理地址E，页大小L。

1. 计算页号P=A/L，和页内偏移量W=A%L。
2. 比较P和页表长度M，若P>=M则说明发生了越界中断
3. P对应的页表项地址=页表始址F+页号P*页表项长度，从地址中取出内容b。页表长度指页数，页表项长度则指页地址长度。
4. E=b*L+W，用E去访存。

页式管理只需要A就能得到对应物理地址，页面大小L是固定的，因此页式管理中的地址空间是一维的。页表项的作用是找到页在内存中的位置，以32位、字节编址、一页4KB为例，地址空间有2^20^页，所以页表项应该大于[20/8]=3B，当然一般会选择更大的页表项让一个页面正好容下整数个页表项，如取为4B，则一页可以放下1K个页表项。

分页管理有两个主要问题：:one:每次方寸操作要进行逻辑地址到物理地址的转换，这一速度必须足够快，否则访存速度会降低。 :two:页表不能太大，否则内存利用率会降低。

具有快表的地址变换：由上述地址变化可以看出，如果页表全部存在内存，则存取一个数据或指令需要两次访存，第一次访问页表，第二次根据地址存取数据，于是引入快表。快表是一个具有并行查找能力的高速缓冲存储器，又称为相联存储器（TLB），用来存放当前访问的若干页表项，以加快地址变换的过程，主存中的页表则被称为慢表。于是地址变换过程如下：CPU给出逻辑地址，硬件进行地址转换后，将页号送入高速缓冲寄存器，并于快表中的所有页号进行比较，若页号在快表内，则从中取出页框号，与偏移量拼接形成物理地址，一次访存完成数据存取；若页号不在快表内，则查找主存中的页表，并将页表项存入快表，根据需要使用相应算法替换页表项。也有些处理机设计成快表和慢表同时查找，快表中找到则终止慢表的查找。一般快表的命中率在90%以上，这样分页带来的速度损失就降低到了10%以下，快表的有效性基于局部性原理。

两级页表：延续上述例子，页表项大小4B，一个进程需要2^20^个页表项，即4MB主存空间，显然过大。对于大进程而言，将整个进程的所有页表项装入内存，明显降低了内存利用率，所以为了压缩页表，引入了二级分页。即使用层次结构的页表，顶级页表只占1个页面，则可以容纳1K个页表项，这些页表项构成了二级页号的索引。通过这种机制节省主存空间，也不用盲目地顺序查找页表项。

#### 分段管理方式

分页管理方式是从计算机地角度考虑设计的，通过硬件实现，提高内存利用率，对用户完全透明。分段则考虑了用户和程序员，以满足方便编程、信息保护、共享和动态链接增长等多方面需要。

分段：段式管理方式按照用户进程中的自然段划分逻辑空间，如用户进程由主程序、两个字程序、栈、和一段数据，则划分为5个段，段内要求连续，段间不连续的地址空间，段号和段内偏移量由用户显式提供，在高级程序设计语言中，这一工作有编译程序完成。

每个进程都有一张逻辑空间与内存空间映射的段表，每个段表项对应进程的一段，段表项记录了段号、该段在内存中的起始地址和段长。段表项实际只有两部分，即段长C和始址。

地址变换：系统中的段表寄存器存放始址F和段表长度M，逻辑地址A，变换如下

1. 从逻辑地址A取出前几位为段号S，后几位段内偏移量W
2. 比较段号S和段表长度M，S>=M则越界中断。
3. 段号S对应的段表项地址=段表始址F+段号S*段表项长度，取出内容中的前几位段长C和段始址b，若段内偏移量W>=C则越界中断
4. E=b+W，用E访存。

段的共享是通过两个作业的段表相应表项指向同一个共享段的物理副本实现的，不能修改的代码称为纯代码或可重入代码，可以共享，可修改的代码和数据不能共享。

段的保护主要有存取控制保护和地址越界保护，与页式管理不同，段式管理不能通过一个整数确定物理地址，必须显式提供段号和段内偏移，因此分段管理的地址空间是二维的。

#### 段页式管理方式

将上述两种管理方式结合，产生了段页式管理方式，逻辑地址分为三部分，段号页号和页内偏移量，每个进程对应一个段表，段表项包括段号、页表长度和页表始址，每个分段对应一张页表，页表项包括页号和块号，还有系统还有一个段表寄存器，指出段表始址和段表长度，（段表寄存器和页表寄存器都用来在页表或段表中寻址以及判断是否越界。）普通的段页式管理一次访问需要三次访存，从段表找到页表始址，从页表找到页帧号，形成物理地址并访问。段页式管理的地址空间同样是二维的。

## （二)虚拟内存管理

### 1.虚拟内存基本概念

传统存储管理具有以下两个特性：:one: ​一次性​，​作业​一次全部装入内存，之后才开始运行:two:驻留性，作业装入内存后，就一直驻留在内存中，直到作业结束。以上两个特性显然了浪费了宝贵的内存资源。

局部性原理：“高速缓存是计算机科学中唯一重要的思想”，Cache、快表、页高速缓存、虚拟内存技术广义上讲，全都是高速缓存技术，这一技术依赖局部性原理，局部性原理适用于程序结构和数据结构，表现在时间局部性和空间局部性两个方面。

基于局部性原理，操作系统将程序需要执行的部分调入内存，并将暂时不实用的内容及时调入外存，以腾出空间给其他程序，以此操作系统好像为用户提供了一个比实际内存大得多的存储器，即虚拟存储器。主要有以下三个特性：:one:多次性，相对于一次性，:two:对换性，相对于驻留性:three:虚拟性，从逻辑上扩充了内存的容量。

虚拟内存的实现需要建立在离散分配的内存管理方式的基础上，一般有三种实现方式：

* 请求分页存储管理
* 请求分段存储管理
* 请求段页式存储管理

以上三种方式都需要一定的硬件支持，主要有:one:一定容量的内存和外存:two:页表​或段表:three:中断机制，（缺页中断）:four:地址变换机构，实现逻辑地址到物理地址的转换。

### 2.请求分页管理方式

请求分页建立在基本分页系统的基础上，增加了请求调页和页面置换功能，是目前最常用的一种实现虚拟存储的方法。

页表：| 页号 | 物理块号 | 状态位P | 访问字段A | 修改位M | 外存地址 |

* 状态位P：指示页是否已经调入内存
* 访问字段A：记录访问次数，供置换算法参考
* 修改位M：记录是否被修改过
* 外存地址：指出外存上的地址，通常为物理块号

缺页中断机制：每次访问的页面不在内存中就产生缺页中断。缺页中断程序阻塞当前进程，检查内存中是否有空间，判断是否需要页面置换以及写回外存等操作，将所需页调入内存，并修改对应页表项。作为中断，缺页中断也需要经历保护CPU环境、分析中断原因、转入缺页中断处理程序、CPU恢复等步骤，但缺页中断是指令执行期间而非指令执行结束后产生和处理的，属于内部终端，一条指令执行期间，也可能产生多次缺页中断。

地址变换机构：首先检索快表，若找到则修改访问位（写指令还需要重置修改位），然后利用页表项中的物理块号和页内地址形成物理地址。若没有找到页表项，则需要到内存中查找，在对比页表项中的状态位P，看是否已经调入内存，如果没有调入，则需要缺页中断。


### 3.页面置换算法

进程运行时，若访问的页面不在内存中需要将其调入，但内存无空闲空间时，就需要调出一页程序或数据，送入磁盘的对换区。选择调出页面的算法就是页面置换算法，好的页面置换算法应该有较低的页面置换频率，和较低的缺页率，应该将不会再访问或较长时间不会再访问的页面调出。

一般而言，换入的页面所占的页框（物理块号）与换出页面相同，所以相应页表项可以只修改页号部分。

#### 最佳置换算法（OPT，optimal)

淘汰永不使用的页面，实际中选择最长时间内不再访问的页面，但由于很难预知哪个页面是未来最长时间不再访问的，所以无法实现该算法。但该算法常用来评价其他算法。最长时间不被访问不等于以后访问次数最小，不能混淆。

#### 先进先出置换算法（FIFO)

优先淘汰最早进入内存的页面，即在内存中驻留时间最久的页面，实现简单，只要排成队列并用指针指向最早的页面即可，但是算法与进程实际运行的规律不适应，还会产生所分配的物理块增大而页故障不减反增的异常现象，这一异常被称为Belady异常，只有FIFO算法会产生。

#### 最近最少使用置换算法（LRU)

选择最近最长时间未被访问的页面进行淘汰，为每个页面设置一个访问字段，记录上次被访问以来经过的时间，与OPT没有必然联系，但性能接近，LRU是“向前看”，而OPT是“向后看”的。LRU性能好，但需要寄存器和栈的硬件支持，开销大，LRU是堆栈类算法，不会出现Belady异常。

#### 时钟置换算法（CLOCK)

利用较小的开销获得接近LRU算法的性能，都是CLOCK的变体，算法需要循环扫面缓冲区，像指针一样转动，所以称为CLOCK。

简单CLOCK给每一个帧关联一个附加位，称为使用位，装入和使用时置1，被扫描到时置0；算法选择被扫描到的第一个使用位是0的页面进行替换，如果所有页面都是0，就选择第一个页面，这一算法又叫最近未用（NRU，Not Recently Used）算法。通过增加使用位的数目，可以让算法更加高效。

在简单CLOCK的基础上增加一个修改位，就变成了改进型CLOCK算法，算法尽可能保留曾经使用过的页面，并优先换出未修改过的页面，以减少写回时间，增加效率。算法执行以下操作确定替换页面：

1. 从指针的当前位置开始，扫描缓冲区，第一步扫面不对使用位进行修改，选择遇到的第一个使用位和修改位为0的页进行替换
2. 1）失败，则重新扫描，查找使用位0，修改位1的页面，遇到的第一个符合条件页面用于替换，对于扫描过的帧，将使用位置0
3. 2）失败，则将指针放回最初位置，此时集合中所有使用位均为0，重复第一步，若有必要再重复第二步。

### 4.页面分配策略

主要包括驻留集大小、页面调入时机、页面调入位置三个部分。

驻留集：给一个进程分配的物理页框的集合就是这个进程的驻留集，每个进程的驻留集越小，内存中的进程数就越多，可以提高处理机的时间效率，但是每个进程的页面过少会导致页错误率较高，但页数大量增加，由于局部性原理，对于错误率不会有明显的影响，所以需要确定一个适当的驻留集大小。一般采用三种分配策略：

1. 固定分配局部置换：为每个进程分配一定的物理块，运行期间不改变数量。问题在于难以确定具体的物理块数量。
2. 可变分配全局置换：最易实现，先给每个进程分配一定数量，操作系统保持一个空闲物理块队列，进程缺页时，操作系统从空闲队列中取出一个空闲块分配给进程，这种方法较为灵活，但OS可能盲目给进程增加物理块，导致并发能力下降。
3. 可变分配局部置换：为每个进程分配一定的物理块，但只有进程频繁发生缺页故障时，才给她增加物理块，若进程缺页率特别低，则减少物理块，这保证了系统的多道程序并发能力，需要更复杂的实现和开销，但相较于频繁换入换出带来的浪费，这种牺牲是值得的。

调入页面的时机：主要有预调页策略和请求调页策略两种，预调页策略就是在运行前调页，请求则是在运行中调页，一般两种策略会同时使用，根据局部性原理，一次调入若干相邻页面会比一次调入一页更为高效，但是目前预测的成功率只有一半，所以这种策略目前主要用于进程的首次调入，由程序员指出应该调入哪些页。而请求调页的缺点是每次只调入一页，页面较多时，会有过大的I/O开销，但因为策略容易实现，而且调入的页面一定会被访问，所以目前的虚拟存储器大多使用此策略。

调入页面的位置，主要有存放文件的文件去和存放对换页面的对换区，对换区一般使用连续分配方式，磁盘I/O速度较快，而文件区离散分配。于是由以下三种情况：

1. 系统对换区空间充足：全部从对换区调入页面，所有相关文件都从文件去复制到对换区，提高调页速度。
2. 系统对换区空间较少：不会被修改的文件都从文件区调入，可能被修改的内容放入对换区，需要时再调取。
3. UNIX方式：未运行过页面都从文件区调入，而换出的页面都放在对换区，共享页面若已在内存则无需调入。

### 5.工作集

工作集指某段时间内，进程需要访问的页面集合，基于局部性原理，可以用最近访问过的页面确定工作集的大小，工作集W，一般由时间t和工作窗口Δ确定，实际应用中Δ会取的很大，而对于局部性好的程序，工作集比Δ小很多。工作集反映了进程在接下来一段时间可能频繁访问的页面集合，一般来说分配给进程的驻留集大小都会大于工作集大小。

工作集模型的原理是，操作系统追踪每个进程的工作集，并给其分配大于工作集的驻留集，如果还有空闲物理块，则可以再调入进程增加多道程序数量，如果所有进程工作集之和大于可用物理块总数，则操作系统选择一个进程暂停并调出页面，将物理块分配给其他进程，防止出现抖动现象。

### 6.抖动

刚换入的页面又被换出、刚换出的页面需要被换入，这种频繁的页面调度行为称为抖动或颠簸，主要原因是进程频繁访问的页面数目高于可用的物理页帧数，稳定状态下，主存的几乎所有空间都被进程块占据，管理不当则会导致处理器的大部分时间都用于交换，即处理缺页请求，而非执行指令，导致系统效率大大降低。

### 地址翻译（结合计组相关内容





# 四、文件管理

## （一)文件系统基础

### 1.文件概念

文件是信息集合，是用户输入输出的基本单位，操作系统提供文件系统来实现文件管理。

文件包括一块存储空间及空间内数据，分类和索引信息，以及访问权限信息。

文件在逻辑上可以分为有结构文件（记录式文件）和无结构文件（流式文件）两种，记录是指一组相关数据项的集合，用于描述一个对象在某些方面的属性，数据项是文件系统中最低级的数据组织形式，分为基本数据项，即某个对象某个属性的一个值，是数据种可命名的最小逻辑数据单位，即原子数据，和组合数据项，由多个数据项组成。

实际上关于文件并没有严格的定义，文件可以是数字、字母、二进制代码，基本访问单元可以是字节、行或记录。文件可以长期存储与硬盘或其他二级存储设备，允许可控制的进程共享访问。

文件的属性有：名称、标识符、类型、位置、大小、保护、创建日期、上次修改时间、上次访问时间、用户表示等。

文件的基本操作有：（文件操作都由系统调用实现）

* 创建：包括两步，找到空间和创建条目，条目中记录名称位置和其他可能信息。
* 写文件：指明文件名称和写入内容，查找文件位置，并维护一个文件内位置的写指针。
* 读文件：指明名称和读入的内存位置，搜索相关目录项，维护一个读位置指针，通常一个进程只读写一个文件，可以将当前操作位置作为当前文件位置的指针，节省空间，降低了操作复杂度。
* 文件重定位（寻址）：按照条件搜索文件
* 删除文件：删除文件的目录项，使其为空，而后回收文件所占的内存空间
* 截断文件：不改变文件的属性，删除文件的内容，将其长度设为0，释放空间。（不同于删除文件，inode保留）

文件的打开与关闭：首次使用文件时，需要用系统调用open()，open函数指明文件属性，将文件属性复制到内存打开文件表（open-file table）中，并将表目（也称索引）返回给进程，进程之后的文件I/O操作都通过open返回的文件指针进行，进程维护一个进程文件打开表，保存进程使用的打开文件的指针，保存fd文件描写叙述符到进程PCB，作为文件打开表项的指针。系统维护打开文件表，表中保存打开文件的FCB（文件控制块，inode），表中每一个文件包含若干个表项，每一个表项对应一个使用该文件的进程，进程打开一个已经在系统打开表中的文件时，文件只需要增加一个表项，返回一个指向inode的指针返回给进程。每个打开文件还关联以下信息：

* 文件打开计数，即文件被多少个进程同时打开，计数为0时，系统将关闭文件，并删除表中条目，
* 文件磁盘位置，文件数据修改时，信息保存在内存中，避免每次操作都涉及硬盘。在文件关闭后写回，上述两项保存在系统文件打开表中。
* 文件指针，文件当前读写位置的指针，和访问权限保存在进程文件打开表中，
* 访问权限，包含每个进程打开文件时的访问模式。

### 2.文件的逻辑结构

文件的逻辑结构是从用户观点看到的文件组织形式，即在文件内部，数据是怎样在逻辑上组织起来的，而文件的物理结构则是在外存上的存储组织形式。结构文件在逻辑上的组织是为数据查找服务的（各形式对应一种数据查找方式）。

#### 无结构文件：

最简单的文件组织形式，按照顺序记录，是有序相关信息项的集合，只能通过穷举搜索，适合对基本信息单位操作不多的文件，如源程序文件、目标代码文件。

#### 有结构文件：

1. 顺序文件：文件中的记录顺序排列，记录通常是定长的，可以顺序存储也可以以链表形式存储，有串结构和顺序结构两种，串通常按照时间顺序，顺序结构则按照关键字排序。在对记录进行批量操作时，顺序文件的效率是最高的，也只有顺序文件能记录在磁带上，但是对于增删改查单条记录较为困难
2. 索引文件：对于变长记录文件，顺序查找的时间开销较大，所以可以建立索引表加快查找速度，索引表本身是定长记录的顺序文件，记录每个记录的起始地址，通过索引可以成百上千倍提高访问速度。
3. 索引顺序文件：是两种组织形式的结合，将顺序的记录分为若干个组，为顺序文件建立一张索引表，为每组第一条记录建立索引项，索引项包括关键字值和指针。记录数很多时，还可以采用多级索引。
4. 散列文件：给定记录的键值通过散列函数转换直接得到物理地址，没有顺序的特性，具有很高的存取速度，但是会引起散列冲突。

### 3.目录结构

#### 文件控制块和索引节点

文件控制块FCB（File Control Block），是用来存放控制文件需要的各种信息的数据结构，FCB的有序集合称为文件目录，一个FCB就是一个文件目录项，主要包括文件基本信息如文件名、物理位置、逻辑结构，存取控制信息如文件存取权限，和使用信息如建立时间、修改时间。但在检索目录文件的时候，只需要使用文件名，所以如UNIX系统就将文件名和文件描述信息分开，描述信息单独构成索引结点的数据结构，简称i结点，文件目录中的目录项就有文件名和指向对应i结点的指针组成。FCB大小64B，而目录项仅需16B（包括14B文件名和2B指针），可以使查找文件的平均磁盘启动次数减少到1/4，大大节省系统开销。

存放在磁盘上的索引结点就是磁盘索引节点。主要包括文件主标识符，文件类型，文件存取权限，文件物理地址，文件长度，文件链接计数，文件存取时间。而在文件被打开时，磁盘索引结点复制到内存索引节点中，增加了索引节点编号、状态（是否上锁或被修改）访问计数、逻辑设备号，链接指针等信息。

#### 单级目录结构和两级目录结构

目录层次所需操作：搜索、增删查改，因此可以考虑以下目录结构。

单级：整个FS值建立一张目录表，每个文件占一个目录项。这一结构实现了按名存取，但是存在查找速度慢、文件不允许重名、不利于共享等缺点，不适用于多用户的操作系统。

两级：文件目录分为主文件目录MFD（Master File Directory）和用户文件目录UFD（User File Directory），解决了不同用户文件重名问题，也在一定程度上保证了文件的安全，实现了访问限制，但是缺乏灵活性，不能分类。

#### 树形目录结构（多级目录结构）

文件路径名是一个字符串，从根目录出发的称为绝对路径，从当前目录出发的叫相对路径，进程对文件的访问都是相对于当前目录进行的，每级目录用分隔符“/”链接。树形目录可以方便的对文件进行分类，层次结构清晰，能够有效的进行文件管理和保护，但是查找文件需要逐级访问中间结点，增加了磁盘访问次数，影响查询速度。

#### 图形目录结构（无环图

树形结构利于文件分类，但不便于文件共享，因此在树形目录的基础上增加一些指向同一节点的有向边，就成为有向无环图，来实现文件共享。

每个结点设置一个共享计数器，用户删除共享节点时，只是删除共享链，并将共享计数器-1，当共享计数器为0时，才真正删除文件，共享不同于文件拷贝（副本），只存在一个真正的文件，每一个用户的修改都对所有共享用户可见。这一目录结构使共享方便，但使管理复杂。

### 4.文件共享

当代计算机文件共享已经从单级到多级，发展到基于网络的文件共享，常用两种共享方式，软链接和硬链接。

基于索引结点的共享，即硬链接。每个用户拥有一个指针指向文件目录项，文件其他属性放在索引结点中，索引节点还保存链接计数count，表示指针数目，用户删除文件时，只删除自己拥有的指针，同时count减1，只有count=0时，系统才删除文件。

基于符号链的共享，即软连接。只有文件拥有者拥有指向索引节点的指针，其他用户只有文件的路径名，其他用户共享时，创建一个LINK类型的文件，文件只包含被链接文件F的路径名，新文件也取名F，这种链接也叫符号链接。这样避免了悬空指针的问题，如果文件不存在，共享者会 出现访问失败，之后会删除符号链。但如果文件所有者删除文件后，又有人在同一路径下建立同名文件，则原有共享符号链依然有效，这种情况可能导致错误。符号链共享时，每次访问都需要通过路径多次读盘，使访问开销增大，符号链的索引结点也会耗费一定磁盘空间，但是符号链有一个很大优点，即网络共享使只需提供网络地址和文件路径即可。

以上两种都是静态共享文件，如果需要两个进程同时对一个文件进行操作，则需要用到动态共享。静态共享由于每次增加链接时都增加了文件名，所以在便利整个文件系统的时候，将会重复遍历共享文件。硬链接将多个指针指向同一索引节点，查找速度要比记录共享文件路径的软链接要快。

### 5.文件保护

文件保护可以通过口令保护、加密保护、访问控制等方式实现，口令和加密是为了防止文件被非法用户访问，访问控制则是控制合法用户的权限。

访问类型：对于文件，可以控制的访问类型主要有以下几种：读、写、执行（装入内存）、添加、删除、列表清单（获取文件名和属性），此外还有复制、重命名、编辑等，高级功能可以通过系统调用低层系统调用实现，所以保护可以只在低层提供，比如复制打印都可以通过读操作实现。

访问控制：解决访问控制的最常用方法是基于用户身份进行控制，最普通的方法就是为每个文件和目录增加一个访问控制列表（Access-Control List，ACL）来规定用户名和允许类型，这种方法的优点是可以使用复杂的访问方法，缺点是长度无法预计且可能导致复杂的空间管理。精简的访问列表则采用所有者（拥有者）、组、其他用户三种类型，这样只需要三个域就可以列出三类用户的访问权限，UNIX操作系统就采用这种方法。

口令和密码是另外两种保护方法。口令地时空开销不大，但是直接保存在系统内部可能不够安全，密码保密性较强，但是编码和译码需要一定时间。

现代操作系统文件保护地常用方法是将访问控制列表和用户、组、其他访问控制方案组合使用，而对于多级目录结构而言，不仅需要保护单个文件，还需要设置目录保护机制，来保护子目录内的文件。

## （二)文件系统实现

### 1.文件系统层次结构

现代操作系统有多种文件系统（FAT，NTFS，ext……），自顶向下描述文件层次结构如下：

0. 用户调用接口：文件系统为用户提供的相关调用
1. 文件目录系统：管理文件目录，管理读写状态信息表、打开文件表等，
2. 存取控制验证模块：实现文件保护，将用户请求和FCB的访问控制权限比较，确认访问合法性
3. 逻辑文件系统和文件信息缓冲区：根据文件逻辑结构将读写的逻辑记录转换成逻辑块号
4. 物理文件系统：将逻辑块号转换成物理地址
5. 辅助分配模块、设备管理模块：辅助分配主要负责空间管理，负则分配空闲空间和回收空间，设备管理模块则是分配设备、读写缓冲区、磁盘调度、设备启动互斥释放中断等管理。

可以根据文件访问过程来理解：用户发出指令到文件系统，文件系统通过文件目录系统定位文件，读出FCB，存取控制验证模块确认操作合法，然后又逻辑文件系统和文件信息缓冲区找到文件内部指针对应的逻辑地址，由物理文件系统通过逻辑地址获得物理地址，最后通过辅助分配模块和设备管理模块进行空间分配、实际访问设备。

### 2.目录实现

目录的实现就是为了查找，所以目录实现方式与查找方式相对应。

线性列表：将文件名和数据块指针储存为线性表，通过每一个目录项来进行创建、删除、查找。重用目录项有多种方法，目录项标记为已删除、添加到空闲目录项表、将最后一个目录项移动到重用位置等，采用链表结构可以减少文件删除的时间开销，这一方法优点在于实现简单，但由于线性表的特性，时间开销较大。

哈希表：通过哈希函数映射文件名和元素指针，优点是查找迅速，插入删除简单，但是需要措施来避免冲突，最大的困难在于表长固定和哈希函数对于表长的依赖。

为了缩减I/O操作，减少开销，可以将当前文件目录复制到内存，可以降低磁盘操作次数，提高速度。

### 3.文件实现

文件实际上是一种ADT，需要研究逻辑、物理结构和相关操作，操作系统主要研究文件分配方式，即对磁盘非空闲块的管理，和存储空间管理，即空闲块管理。

#### 文件分配方式

主要有三种，连续分配、连接分配和索引分配，大部分操作系统只支持一种，但也有RDOS系统同时支持三种方法。

1. 连续分配：占用磁盘上一组连续的块，这种排序的磁盘访问你寻道数和寻道时间最小。这种方式下，文件的盘块分配可以有首块地址和连续盘块数量定义，支持顺序访问和直接访问，优点是实现简单、存取速度快，缺点是文件长度不宜动态增加，反复增删文件后会产生外部碎片，所以这一方法适应长度固定的文件。
2. 链接分配：采用离散分配的方式，消除外部碎片，于是显著提高磁盘空间利用率，根据文件需要分配盘块，适应文件动态增长，方便增删改，可以分为隐式链接和显式链接两种方式。
   1. 显式分配是把链接文件各物理块的指针显式存放在内存的一张链接表中，称为文件分配表（File Allocation Table，FAT），每个表项存放对应块的下一个链接地址，即下一个盘块好，文件的所有盘块都可以查询FAT找到，文件分配表不仅记录了文件先后链接关系，还能通过负数值标记空闲磁盘块，操作系统也可以利用FAT对存储空间进行管理。为了提高检索速度，FAT表在系统启动时就读入内存，减少了磁盘访问次数。
   2. 隐式链接分配，下一盘块的盘块指针存储在盘块末尾，文件目录只包含文件首指针和尾指针，初始化时，设置首指针为NULL表示空，写文件时将空闲块链接到文件尾部，缺点是无法直接访问盘块，只能顺序访问，而且盘块指针也会消耗一定存储空间，文件稳定性也有问题，任何一个链表中的指针丢失或损坏都会导致文件数据丢失。
3. 索引分配：解决链接分配难以直接访问的问题，把每个文件的所有盘块号集中在一起称为索引块（索引表），每个文件都有索引块，这是一个磁盘块地址数组，但由于每个文件都必须有一个索引块，所以索引块应尽可能小，但是索引块小就很难有效支持大文件，所以诞生了以下机制：
   1. 链接方案：多个索引块链接起来表示大文件
   2. 多层索引：第一层索引块指向第二层索引块，第二层索引块再指向文件块，如4096B空间可以放下1024个4B指针，两层索引就允许最大文件为4GB。
   3. 混合索引：多种索引分配方式相结合，如UNIX系统中，每个inode设置13个地址，0-9为直接地址，直接存放盘块号，支持40KB大小的文件，iaddr(10)则存放一次间址，1024个盘块号，文件支持4MB，iaddr(11)提供二次间址，支持4GB，12提供三次间址，支持4TB。

三种文件分配方式比较：

| 名称     | 访问第n条记录            | 优点                                                         | 缺点                                                         |
| -------- | ------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 连续分配 | 访问磁盘1次              | 顺序存取速度快，文件定长时，可以根据始址和记录长度实现随机访问 | 文件存储要求连续存储空间，会产生外部碎片，也不利于文件的动态扩充。 |
| 链接分配 | 访问磁盘n次（n个块）     | 解决外部碎片问题，提高空间利用率，方便动态增长               | 只能按照指针链顺序访问，查找效率低，指针信息存放消耗空间。   |
| 索引分配 | 访问磁盘m+1次（m级索引） | 可以随机访问，文件易于增删                                   | 索引表增加了存储空间开销，索引表的查找策略对于文件系统的效率影响较大。 |

由此每次访问文件需要先读取索引块，在访问磁盘块，可能导致速度较慢，所以通常将文件的索引块读入内存缓冲区，加快文件访问速度。

![Linux文件系统](https://images2018.cnblogs.com/blog/748759/201712/748759-20171209173333308-1173170440.jpg)

#### 存储空间管理

文件存储在文件卷中，一个卷可以是一个物理盘的一部分、全部甚至多个物理盘。文件卷中文件区和存放FCB的目录区是分开的。存储器空间初始化时，会建立空闲空间管理表和存放逻辑卷信息的超级块，划分文件区和目录区等。实际上在ext2中，包括Boot Block启动扇区，Super Block超级块，GDT全局描述表，Block Bitmap块对照表，inode Bitmap，inode表，以及Data Blocks数据块。

对于文件存储空间的管理实质上就是对空闲块的组织和管理，包括组织、分配、回收等问题

1. 空闲表法：属于连续分配方法，与内存动态分配类似，为每个文件分配一块连续的存储空间，所有空闲区则建立一张空闲盘块表，每个空闲区对应一个表项，包括序号、首块号、盘块数，并按照起始盘块号之恩的顺序排列。空间分配与内存动态分配类似，采用首次适应算法、循环首次适应算法等，回收也类似于内存回收，需要考虑合并问题。
2. 空闲链表法：分为空闲盘块链和空闲盘区链，盘块链的优点分配和回收盘块过程简单，缺点是为一个文件分配需要多次重复操作。空闲盘区链将盘区拉成一条链，其他一致。空闲链表分配也与内存分区分配类似，通常采用首次适应算法。盘区回收时也要考虑合并问题。
3. 位示图法（Block Bitmap）：用二进制的一位来表示一个盘块的使用情况。盘块分配时，顺序扫描bitmap，找到一个或一组值为0的二进制位，计算盘块号。回收时正好相反。 
4. 成组链接法：UNIX系统使用的方法，结合了空闲表和空闲链表，把顺序的n个空闲扇区地址保存在第一个空闲扇区内，其后一个空闲扇区则保存另一个空闲扇区的地址，表示文件存储器空闲空间的“位向量”表或第一个成组链接块，以及卷中的目录区、文件区划分信息都存放在超级块中，超级块需要预先读入系统主存，并保持一致性。

## （三)磁盘组织与管理

### 1.磁盘的结构

磁盘是表面涂有磁性材料的圆盘，通过磁头的导体线圈存取数据，磁头固定，磁盘旋转，磁盘上的数据存在一组同心圆中，称为磁道，磁道又划分为几百个扇区，每个扇区固定存储大小，（512B），一个扇区也称为一个盘块，磁盘存储密度从外道向里道增加，磁盘的存储能力受限于最内道德最大记录密度。磁盘由磁头臂、主轴、和控制电路组成，扇区是磁盘可寻址的最小存储单元。磁盘可以分为固定头磁盘、活动头磁盘、固定盘磁盘、可换盘磁盘等。

### 2.磁盘调度算法

一次磁盘读写操作的时间由寻找时间（寻道）、延迟时间、传输时间决定。

寻找时间T~s~=m×n+s，即启动磁盘时间s，约为2ms，跨越n个磁道，m是与磁盘驱动器相关的常数，约为0.2ms。

延迟时间T~r~=1/2r，r为磁盘旋转速度，对于5400转/分的的T~r~约为5.55ms。

传输时间T~t~=b/rN，b为字节数，r为每秒转数，N为一个磁道上的字节数。

总的存取时间T~a~=T~s~+1/2r+b/rN，但在实际的磁盘I/O操作中，存取时间和磁盘调度算法相关，调度算法直接决定寻找时间，，从而决定总存取时间。

1.  先来先服务（First Come First Severd，FCFS），这是最简单的算法，具有公平性，在少量进程簇聚访问下可能有较好的性能，大量进程竞争则接近于随机调度，所以实际中会使用更复杂的调度算法。
2. 最短寻找优先（Shortest Seek Time First，SSTF），选择距离当前磁道最近的磁道，使每次寻找时间最短，但是局部最优不保证整体最优，但是这种算法可能产生“饥饿”现象。
3. 扫描算法（SCAN，也叫电梯算法）：在最短寻找时间优先的算法基础上，规定了磁头运动的方向，但是SCAN对于最近扫描过的区域不公平，访问局部性方面不如FCFS和SSTF。
4. 循环扫描（Circular SCAN，C-SCAN）：在扫描的基础上规定磁头单向移动，回返时直接移动到起始端而不服务任何请求，克服了SCAN偏向于处理最里或最外的磁道访问请求的缺点。
5. LOOK、C-LOOK，磁头移动只需到达最远的一个请求而非最远端，使SCAN算法的改进，在一些题目中也可以将SCAN当做LOOK算法。

| 算法             | 优点                       | 缺点                                      |
| ---------------- | -------------------------- | ----------------------------------------- |
| FCFS             | 公平、简单                 | 平均寻道距离大，仅应用在磁盘I/O较少的场合 |
| SSTF             | 性能比先来先服务好         | 不能保证平均寻道时间最短，可能出现“饥饿”  |
| SCAN（LOOK）     | 寻道性能较好，可以避免饥饿 | 不利于原理磁头一端的访问                  |
| C-SCAN（C-LOOK） | 消除对两端磁道请求的不公平 | —                                         |

除了减少寻找时间，减少延迟时间也是提高传输效率的重要因素，可以对盘面扇区进行交替编号，即对磁盘片组中的不同盘面错位命名。在一个磁道用完时，应该优先使用同一柱面不同盘面的磁道，而同柱面不同盘面的扇区错位编号，则读写两个盘面的逻辑记录也能减少磁头延迟时间。

传输时间是磁盘本身性质决定的，所以不能减少。

### 3.磁盘的管理

1. 初始化：首先需要进行低级格式化（物理分区），为磁盘的每个每个扇区采用特别的数据结构，每个扇区的数据结构通常由头和数据取组成。之后进行逻辑格式化（创建文件系统），通过操作系统将初始化的文件系统数据结构存在磁盘上，这些数据结构包括空闲和已分配的空间和一个初始为空的目录。
2. 引导块：计算机启动需要运行初始化程序（自举程序），自举程序通常保存在ROM中，但ROM容量有限，所以一般只保留很小的自举装入程序，但完整的自举程序保存在磁盘的固定位的启动块中，拥有启动块的磁盘称为启动磁盘或系统磁盘。
3. 坏块：磁盘有移动部件且容错能力弱，因此容易导致一个或多个扇区损坏，对于简单磁盘，坏扇区会在FAT表上标明；对于复杂的硬盘，控制器维护一个磁盘坏块链表，低级格式化会将一些块留作备用，对操作系统透明，控制器可以用备用快来逻辑替代坏块，称为扇区备用。坏块是硬件故障，操作系统是不能干预的。

# 五、输入输出## （I/O)管理

## （一)I/O管理概述

分类：

1. 使用特性：人机交互类、存储设备、网络通信设备
2. 传输速率：低速设备、中速设备、高速设备
3. 信息交换单位：块设备、字符设备，块设备传输速率高、可寻址，可以随机读写。

### 1.I/O控制方式

1. 程序直接控制：CPU直接控制I/O，控制方式简单易于实现，但是CPU只能跟I/O串行，导致CPU利用率低。
2. 中断驱动方式：I/O设备在传输完成后，中断CPU，比程序直接控制有效，但由CPU控制，仍然消耗较多CPU时间。
3. DMA方式（直接存储器存取：基本单位是数据块，传送数据直接从设备到内存，整块数据传送在DMA控制下进行，只有一块开始结束才需要CPU干预。
4. 通道控制方式：通道是一种专门处理I/O的处理机，是DMA的发展，CPU只需向通道发送一条I/O指令，就能实现I/O，传输的位置、大小等信息都有通道控制，DMA只能对应一台设备和内存传输，通道则可以控制多台设备和内存数据交换。

### 2. I/O软件层次结构 

I/O软件涉及的面非常广，往下和硬件密切联系，往上和用户直接交互，为了有清晰的结构、良好的可移指和适应性，普遍采用层次结构

1. 用户层I/O软件： 实现与用户交互的接口，大部分I/O软件都在操作系统内部，所以用户层软件必须通过一组系统调用来获取操作系统服务。
2. 设备独立性软件：设备独立性也叫设备无关性，使应用程序独立于具体物理设备，引入逻辑设备和物理设备的概念，应用程序只使用逻辑设备名来请求，好处是增加了设备分配的灵活性，易于I/O重定向。总体来说，独立性软件的功能分为两方面：执行所有设备的共有操作，包括分配回收、逻辑名映射，设备保护、缓冲、差错控制、提供独立的逻辑块，屏蔽设备之间信息交换单位的大小、传输速度差异等；以及向用户层提供统一接口，如read/write指令。
3. 设备驱动程序：与硬件直接相关，负责具体实现系统对设备发出操作指令，驱动I/O设备工作，通常每类设备配置一个设备驱动程序，使I/O进程和设备控制器之间的通信程序，常以进程的形式存在，为I/O内核子系统隐藏设备控制器之间的差异。
4. 中断处理程序：进行进程上下文的切换，负责相关中断。
5. 硬件设备：通常包括电子部件和机械部件，电子部件称为设备控制器、配适器。

设备控制器通过寄存器与CPU通信，有些计算机上，这些寄存器使用内存地址的一部分，称为内存映像I/O，另一些则采用专用地址。CPU通过控制寄存器读取的信息判断执行结果和设备新的状态信息， 。

设备控制器的主要功能有：接受和识别命令，实现数据交换，发现和记录设备以及自身的状态信息，设备地址识别。所以设备控制器需要包括以下组成部分：设备控制器与CPU的接口，设备控制器与设备的接口，I/O控制逻辑。

## （二)I/O核心子系统

I/O设备种类繁多，功能和传输差异巨大，需要多种方法进行设备控制，这些方法组成了I/O子系统，主要提供I/O调度、缓冲、设备分配回收、假脱机、设备保护和差错处理等。

### 1.I/O调度概念

 I/O调度就是确定一个好的顺序执行I/O请求，是进程之间公平共享设备访问，减少I/O平均等待时间，操作系统通过为每一个设备维护一个请求队列来实现调度，

###2.高速缓存与缓冲区

1. 磁盘高速缓存（Disk Cache）磁盘高速缓存在逻辑上属于磁盘，物理上则是驻留在内存中的盘块，，分为两种形式，一种是在内存中开辟一个单独空间作为磁盘高速缓存，大小固定；另一种是把未利用地内存空间作为一个缓冲池，供请求分页和磁盘I/O共享。

2. 缓冲区（Buffer）：引入缓冲区主要目的是解决设备间速度不匹配的矛盾，减少对CPU的中断频率，放宽对CPU中断响应时间的限制，解决基本数据单元大小即数据粒度不匹配的问题，提高CPU和I/O设备之间的并行性。实现方法有硬件缓冲器和内存缓冲区，缓冲器成本太高，只在关键部位使用。缓冲区的特点是，只有数据空才冲入，充满后才读出，非空不能冲入数据，非满不能读出数据，
   1. 单缓冲：设备和处理机之间设置一个缓冲区，假定磁盘输入一块数据为T，操作系统传送到用户区用时M，CPU处理时间为C，则处理每块数据的用时为max（C，T）+M。
   2. 双缓冲：单缓冲下，CPU在传送时间M空闲，所以引入双缓冲，在设备输入时，先装填到缓冲区1，填满后装填2，处理一块数据用时则是max（C+M，T），若C+M<T则块设备可以连续输入，若C+M>T则CPU不必等待设备输入。此外，双缓冲还可以实现全双工通信，作为双向数据缓冲。
   3. 循环缓冲：多个大小相等的缓冲区，以指针相互指向，多个缓冲区构成一个环形。in和out两个指针指向可以输入数据和提取数据的两个缓冲区。
   4. 缓冲池：多个系统公用的缓冲区组成，根据使用情况排成三个队列，空缓冲队列，满输入缓冲队列和装满输出的队列。应该具有4种缓冲区，收容输入的hin，提取输入的sin，提取输出的sout，收容输入的hout。
   
3. 高速缓存和缓冲对比：都位于高低速设备之间。

   | 区别 | 高速缓存                                                     | 缓冲区                                           |
   | ---- | ------------------------------------------------------------ | ------------------------------------------------ |
   | 数据 | 存放副本数据，高速缓存有的，低速设备上一定有                 | 存放的是传递中的数据，在设备上不一定有备份       |
   | 目的 | 存放的是高速设备经常要访问的数据，若未命中，则需要访问低速设备 | 所有通信经过缓冲区，高速设备不会直接访问低速设备 |

   





###3.设备分配与回收

　　

###4.假脱机技术（SPOOLing)

 